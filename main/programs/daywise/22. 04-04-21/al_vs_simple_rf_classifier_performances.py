import matplotlib.pyplot as plt
from modAL.uncertainty import entropy_sampling
x = []
for i in range(0, 499):
    x.append(i)
y1 = [0.498632,0.497976,0.500055,0.492614,0.499836,0.498085,0.494584,0.505745,0.501805,0.499726,0.510997,0.506948,0.507933,0.506948,0.509465,0.518328,0.517781,0.511106,0.510997,0.512857,0.517562,0.514608,0.517234,0.511872,0.515811,0.519532,0.517343,0.515155,0.512419,0.518656,0.508918,0.519641,0.523690,0.523143,0.522048,0.520845,0.522377,0.519532,0.520735,0.519203,0.523909,0.520188,0.526972,0.524674,0.521830,0.527082,0.529161,0.526972,0.524784,0.529051,0.527848,0.529161,0.528285,0.522267,0.530036,0.523799,0.536054,0.536930,0.536273,0.539556,0.537148,0.542072,0.541854,0.545355,0.542948,0.540541,0.536164,0.538133,0.539665,0.544808,0.534741,0.544370,0.540322,0.543276,0.542510,0.545246,0.546449,0.552577,0.547434,0.547106,0.549513,0.546668,0.553124,0.547325,0.544808,0.553562,0.551483,0.551154,0.552577,0.549513,0.549075,0.551373,0.554546,0.554984,0.555641,0.557173,0.555750,0.553999,0.556297,0.556735,0.557173,0.548091,0.555641,0.557501,0.553562,0.555641,0.555750,0.553124,0.557720,0.556297,0.557173,0.552139,0.555203,0.558267,0.552139,0.558814,0.556844,0.555750,0.555422,0.558157,0.558376,0.556516,0.556844,0.560674,0.558267,0.560127,0.556844,0.560565,0.560455,0.558923,0.559799,0.558157,0.558704,0.561002,0.559252,0.561878,0.558704,0.556844,0.561331,0.559799,0.558157,0.563081,0.554765,0.558595,0.563081,0.558486,0.562315,0.561112,0.561112,0.561878,0.565270,0.565489,0.559580,0.559361,0.565160,0.561549,0.567349,0.558814,0.569428,0.564613,0.570303,0.566473,0.569865,0.569428,0.568771,0.570303,0.565926,0.566802,0.572163,0.570960,0.570084,0.571288,0.572273,0.571178,0.569428,0.573695,0.570303,0.571288,0.574023,0.573367,0.571616,0.573914,0.573476,0.570960,0.576540,0.571507,0.576431,0.569428,0.574680,0.573367,0.576650,0.574133,0.575884,0.574461,0.578510,0.575665,0.580917,0.580698,0.574680,0.576102,0.579932,0.577744,0.576321,0.575774,0.573914,0.576540,0.581355,0.576540,0.579385,0.581136,0.577415,0.578947,0.579932,0.578838,0.580698,0.575993,0.583981,0.578181,0.579604,0.583543,0.583434,0.583105,0.585294,0.578729,0.583981,0.584528,0.582887,0.582230,0.579385,0.585513,0.585403,0.587154,0.582121,0.589014,0.586935,0.588795,0.589780,0.592734,0.587045,0.588248,0.586497,0.590655,0.585731,0.587701,0.587263,0.587920,0.585841,0.587810,0.586497,0.592078,0.591968,0.592734,0.588248,0.589561,0.589999,0.593063,0.592187,0.591968,0.595142,0.597440,0.593172,0.590874,0.595032,0.591531,0.597440,0.596564,0.595689,0.599847,0.597002,0.592625,0.593282,0.593610,0.592406,0.602254,0.596126,0.597877,0.596674,0.596674,0.598424,0.596236,0.600175,0.596783,0.599956,0.601050,0.595908,0.592734,0.595142,0.597440,0.601707,0.600503,0.599081,0.599628,0.596892,0.600613,0.601269,0.598971,0.606303,0.601816,0.603020,0.596455,0.601379,0.601598,0.601269,0.601926,0.598643,0.598643,0.599081,0.599081,0.599190,0.602911,0.602911,0.606631,0.603348,0.604005,0.605427,0.607069,0.604114,0.609038,0.605208,0.606412,0.607397,0.607178,0.607944,0.610461,0.611008,0.606084,0.606303,0.607287,0.604552,0.606193,0.609695,0.606850,0.604224,0.605318,0.606959,0.604333,0.605756,0.605537,0.608272,0.606959,0.609476,0.608601,0.607944,0.608382,0.610023,0.610023,0.610570,0.610898,0.608819,0.611008,0.612321,0.616588,0.612977,0.610242,0.615494,0.616369,0.610898,0.610680,0.615494,0.613415,0.617245,0.617135,0.614181,0.617135,0.618011,0.615713,0.617682,0.619214,0.618448,0.616151,0.614947,0.619980,0.618011,0.618339,0.617901,0.619324,0.616369,0.617573,0.619543,0.616479,0.618777,0.616479,0.617901,0.618339,0.618230,0.621731,0.620637,0.619871,0.618777,0.617682,0.621403,0.620856,0.622388,0.620746,0.621731,0.623044,0.619871,0.622278,0.621403,0.621622,0.619105,0.623154,0.621512,0.622935,0.620965,0.621731,0.621622,0.624248,0.622606,0.618996,0.620637,0.623810,0.623591,0.620746,0.622278,0.621403,0.623482,0.623919,0.623372,0.625123,0.624029,0.624138,0.622935,0.621403,0.623044,0.622606,0.624576,0.626655,0.626764,0.625780,0.626108,0.625780,0.625342,0.626983,0.625889,0.627968,0.626764,0.625889,0.626983,0.628077,0.626217,0.625998,0.625889,0.628187,0.625342,0.628734,0.628296,0.628953,0.626983,0.629172,0.626764,0.627749,0.628077,0.626874,0.627421,0.628625,0.626874,0.628843,0.626874,0.627530,0.627640,0.629172,0.627530,0.627202,0.629062,0.625451,0.628077,0.629172,0.627421,0.629828,0.629062,0.628734,0.631251,0.628515,0.631688,0.630375,0.629609,0.629828,0.630266,0.630156,0.629391,0.629172,0.629281,0.630594,0.630704,0.628187,0.627202,0.630375,0.631141,0.631579,0.631360,0.631360,0.631032,0.629062,0.632017,0.633439,0.631360,0.631141,0.631579]
plt.scatter(x, y1, label = "Active Learning")

x2 = [100,200,300,400,500]
y2 = [0.495459,0.496116,0.495897,0.496116,0.497210,0.497210,0.498960,0.495897,0.498304,0.491848,0.504103,0.501258,0.500383,0.495459,0.497429,0.498304,0.497647,0.495897,0.493927,0.496225,0.497757,0.497429,0.493599,0.497866,0.497757,0.492395,0.500164,0.499726,0.495568,0.495459,0.501040,0.502571,0.496991,0.494912,0.500055,0.496881,0.498413,0.498085,0.499836,0.497866,0.496663,0.501040,0.498523,0.499726,0.499945,0.500492,0.495568,0.497210,0.498413,0.495021,0.496225,0.498523,0.496991,0.503775,0.499179,0.500274,0.498413,0.503666,0.495459,0.498632,0.498523,0.496772,0.496991,0.497976,0.499070,0.497429,0.495897,0.498523,0.494474,0.498195,0.495350,0.495240,0.498413,0.495568,0.495131,0.496334,0.495568,0.497210,0.494255,0.502571,0.503994,0.502243,0.503994,0.502243,0.507386,0.507824,0.513623,0.503775,0.509137,0.511653,0.510121,0.514717,0.512748,0.511763,0.507495,0.513514,0.512200,0.513185,0.523471,0.519313,0.515921,0.520516,0.518000,0.517672,0.524674,0.519969,0.521501,0.518875,0.518000,0.521064,0.522158,0.519969,0.524127,0.525331,0.522377,0.522924,0.519313,0.525222,0.518985,0.523799,0.519751,0.520954,0.518437,0.519532,0.515483,0.524784,0.530146,0.519313,0.519203,0.522267,0.520407,0.524237,0.522048,0.522924,0.521830,0.525003,0.520735,0.519641,0.521173,0.525331,0.521173,0.521064,0.528832,0.522705,0.524674,0.522048,0.525878,0.519094,0.522924,0.523471,0.526316,0.525003,0.526753,0.526535,0.527191,0.532115,0.530583,0.528942,0.530802,0.529927,0.530802,0.531568,0.531459,0.532443,0.530802,0.533866,0.538024,0.534413,0.535945,0.536711,0.536054,0.534413,0.538790,0.539009,0.537039,0.541854,0.536601,0.537696,0.540431,0.537696,0.535617,0.538243,0.540103,0.543385,0.540103,0.540541,0.544480,0.540103,0.543167,0.542072,0.544151,0.540431,0.544699,0.540431,0.542729,0.543823,0.541854,0.543167,0.543276,0.539665,0.541088,0.541306,0.541416,0.543823,0.546668,0.544808,0.546230,0.547106,0.546340,0.546996,0.543714,0.545574,0.545574,0.543823,0.547543,0.546012,0.546668,0.545793,0.544808,0.547106,0.543823,0.550170,0.547325,0.550279,0.546121,0.549951,0.547981,0.547653,0.547434,0.550498,0.549513,0.550060,0.554546,0.557391,0.559470,0.556625,0.559689,0.560346,0.562315,0.560018,0.564504,0.565817,0.566692,0.568990,0.565379,0.566692,0.565270,0.566692,0.567896,0.568115,0.574023,0.570960,0.571288,0.570522,0.573914,0.575118,0.572820,0.575446,0.573476,0.574133,0.567786,0.575665,0.575336,0.569537,0.575774,0.570303,0.572820,0.572710,0.571944,0.575884,0.577963,0.575118,0.574023,0.576650,0.575336,0.575774,0.577525,0.575665,0.573805,0.576540,0.575008,0.571178,0.575665,0.576540,0.576868,0.576102,0.575555,0.579604,0.575118,0.575227,0.575774,0.581355,0.578510,0.574571,0.577963,0.576759,0.576321,0.579494,0.578400,0.577306,0.576212,0.577634,0.576431,0.576650,0.573367,0.576102,0.578072,0.572163,0.576650,0.577306,0.576868,0.578619,0.578291,0.573914,0.572601,0.575884,0.574899,0.582339,0.575446,0.571507,0.575774,0.575993,0.579604,0.575774,0.580260,0.577853,0.575336,0.577744,0.577197,0.577853,0.575336,0.573805,0.572163,0.573476,0.574899,0.574899,0.576759,0.578510,0.574461,0.572163,0.578510,0.577306,0.578947,0.576650,0.574352,0.576868,0.577415,0.571726,0.579494,0.575227,0.574133,0.577634,0.576978,0.573914,0.575774,0.572820,0.577525,0.574133,0.574899,0.580151,0.577087,0.572163,0.575993,0.572492,0.570741,0.572382,0.571944,0.573257,0.573805,0.580808,0.572273,0.573039,0.575774,0.571178,0.574023,0.575446,0.573914,0.575008,0.573914,0.569756,0.570522,0.569647,0.575446,0.572382,0.575118,0.573148,0.574133,0.576431,0.574352,0.575446,0.575555,0.575446,0.571944,0.577087,0.569428,0.572273,0.570522,0.573039,0.571397,0.572929,0.569756,0.573148,0.572054,0.567568,0.573367,0.571835,0.570631,0.567568,0.571726,0.572273,0.571726,0.570303,0.575118,0.574242,0.569647,0.569428,0.573367,0.573367,0.566473,0.574133,0.572382,0.573039,0.572710,0.571288,0.570413,0.568552,0.570194,0.573695,0.570194,0.572054,0.571616,0.571178,0.575227,0.572492,0.570522,0.569865,0.566583,0.566255,0.569318,0.568005,0.563847,0.569537,0.569099,0.566145,0.568005,0.567896,0.569865,0.568224,0.566473,0.563628,0.568005,0.567568,0.566473,0.568771,0.564613,0.569428,0.569209,0.569865,0.563300,0.570413,0.568552,0.566145,0.567130,0.565926,0.566583,0.566583,0.566692,0.567239,0.568771,0.566473,0.568990,0.567786,0.567677,0.566036,0.565489,0.564941,0.570084,0.562206,0.563847,0.568990,0.567568,0.581902,0.589889,0.590437,0.591859,0.589999,0.589889,0.589452,0.589233,0.590984,0.592078,0.593282,0.593829,0.595579,0.595908,0.590327,0.597987,0.593063,0.598424]
plt.scatter(x, y2, label = "Random Forest Classifier")

plt.xlabel('Samples')
plt.ylabel('Performance')
plt.title('Performance measure on active learning vs RF classifier')
plt.legend()
plt.show()
